{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임계값 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmhcm\\AppData\\Local\\Temp\\ipykernel_23884\\4114310647.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드 함수\n",
    "def download_pageviews(year, month, day, hour):\n",
    "    url = f\"https://dumps.wikimedia.org/other/pageviews/{year}/{year}-{month:0>2}/pageviews-{year}{month:0>2}{day:0>2}-{hour:0>2}0000.gz\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # 파일 형식 확인\n",
    "        if response.headers.get('Content-Type') == 'application/gzip' or url.endswith('.gz'):\n",
    "            return response.content\n",
    "        else:\n",
    "            raise ValueError(\"The downloaded file is not a GZIP file.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "# GZIP 파일 추출 함수\n",
    "def extract_gz(data):\n",
    "    with gzip.open(BytesIO(data), 'rb') as f:\n",
    "        return f.read().decode('utf-8')\n",
    "\n",
    "# 데이터 파싱 함수\n",
    "def parse_to_dataframe(data):\n",
    "    lines = data.split('\\n')\n",
    "    records = [line.split() for line in lines if line]\n",
    "    df = pd.DataFrame(records, columns=['LanguageCode', 'PageTitle', 'PageViews', 'Metadata'])\n",
    "    return df\n",
    "\n",
    "# 데이터 다운로드 및 추출 함수\n",
    "def fetch_pageviews_to_dataframe(year, month, day, hour):\n",
    "    gz_data = download_pageviews(year, month, day, hour)\n",
    "    extracted_data = extract_gz(gz_data)\n",
    "    df = parse_to_dataframe(extracted_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제 함수\n",
    "def clean_data(df):\n",
    "    # 컬럼명 변경\n",
    "    df.columns = ['LanguageCode', 'PageTitle', 'PageViews', 'Metadata']\n",
    "    \n",
    "    # Metadata 컬럼 DROP\n",
    "    df.drop(columns=['Metadata'], inplace=True)\n",
    "    \n",
    "    # 결측치 처리 및 데이터 타입 변환\n",
    "    df['PageViews'] = df['PageViews'].fillna(0).astype(int)\n",
    "    \n",
    "    # 페이지뷰 기준으로 필터링 (임계값 100)\n",
    "    df = df[df['PageViews'] >= 100]\n",
    "    \n",
    "    # 페이지뷰 기준으로 정렬\n",
    "    df_sorted = df.sort_values(by='PageViews', ascending=False)\n",
    "    \n",
    "    # 제외할 페이지 접두사\n",
    "    exclude_prefixes = [\n",
    "        \"Main_Page\", \"Special:\", \"Talk:\", \"User:\", \"User talk:\", \n",
    "        \"Category:\", \"Portal:\", \"File:\", \"Template:\", \"Help:\", \"Wikipedia:\",\n",
    "        \"MediaWiki:\", \"Spécial:\", \"メインページ\"\n",
    "    ]\n",
    "    df_filtered = df_sorted[~df_sorted['PageTitle'].str.startswith(tuple(exclude_prefixes))]\n",
    "    \n",
    "    # 언어 코드 필터링\n",
    "    language_counts = df_filtered['LanguageCode'].value_counts()\n",
    "    languages_to_remove = language_counts[language_counts <= 10].index\n",
    "    df_filtered = df_filtered[~df_filtered['LanguageCode'].isin(languages_to_remove)]\n",
    "    \n",
    "    # PageTitle 양옆 공백 제거 및 언더스코어 처리\n",
    "    df_filtered['PageTitle'] = df_filtered['PageTitle'].str.strip()\n",
    "    df_filtered['PageTitle'] = df_filtered.apply(\n",
    "        lambda row: row['PageTitle'].replace('_', ' ') if row['LanguageCode'] != 'ar' else row['PageTitle'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Country 컬럼 생성\n",
    "    language_to_country = {\n",
    "        'en': 'United States', 'ar': 'Saudi Arabia', 'zh': 'China',\n",
    "        'es': 'Spain', 'fr': 'France', 'de': 'Germany', 'ru': 'Russia',\n",
    "        'ko': 'Korea', 'ja': 'Japan', 'fa': 'Iran', 'vi': 'Vietnam',\n",
    "        'he': 'Israel', 'id': 'Indonesia', 'it': 'Italy', 'pl': 'Poland',\n",
    "        'pt': 'Portugal', 'tl': 'Philippines', 'tr': 'Turkey',\n",
    "    }\n",
    "    \n",
    "    df_filtered['Country'] = df_filtered['LanguageCode'].str.split('.').str[0].map(language_to_country)\n",
    "    \n",
    "    # URL 컬럼 생성\n",
    "    df_filtered['URL'] = df_filtered.apply(\n",
    "        lambda row: f\"https://{row['LanguageCode']}.wikipedia.org/wiki/{row['PageTitle'].replace(' ', '_')}\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 인덱스 리셋\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LanguageCode       PageTitle  PageViews        Country  \\\n",
      "0         en.m    Simone Biles      79720  United States   \n",
      "1         en.m  Jonathan Owens      38655  United States   \n",
      "2           en               -      34618  United States   \n",
      "3         en.m      Sunisa Lee      27695  United States   \n",
      "4         en.m   Jordan Chiles      25307  United States   \n",
      "\n",
      "                                              URL  \n",
      "0    https://en.m.wikipedia.org/wiki/Simone_Biles  \n",
      "1  https://en.m.wikipedia.org/wiki/Jonathan_Owens  \n",
      "2                 https://en.wikipedia.org/wiki/-  \n",
      "3      https://en.m.wikipedia.org/wiki/Sunisa_Lee  \n",
      "4   https://en.m.wikipedia.org/wiki/Jordan_Chiles  \n"
     ]
    }
   ],
   "source": [
    "# 예제 실행\n",
    "year, month, day, hour = 2024, 7, 31, 1\n",
    "df = fetch_pageviews_to_dataframe(year, month, day, hour)\n",
    "cleaned_df = clean_data(df)\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10073 entries, 0 to 10072\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   LanguageCode  10073 non-null  object\n",
      " 1   PageTitle     10073 non-null  object\n",
      " 2   PageViews     10073 non-null  int32 \n",
      " 3   Country       10073 non-null  object\n",
      " 4   URL           10073 non-null  object\n",
      "dtypes: int32(1), object(4)\n",
      "memory usage: 354.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
